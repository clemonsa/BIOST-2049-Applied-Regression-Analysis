---
title: "DA6_2021_R_Key"
author: "Arvon Clemons II"
date: "4/14/2021"
output:
  pdf_document:
    toc: yes
  html_document:
    df_print: paged
    toc: yes
---

## Libraries
```{r}
library(ggplot2)
```


## Import Data
```{r}
DA6 <- read.csv("./da6.csv")

# factor categorical variables
DA6$health <- factor(DA6$health)
DA6$sex <- factor(DA6$sex)
DA6$adldiff <- factor(DA6$adldiff)
DA6$race <- factor(DA6$race)
DA6$privins <- factor(DA6$privins)
```

```{r Custom Functions, include = FALSE}
log_summary <- function(x, robust = FALSE, irr = FALSE){
  stopifnot("glm" %in% class(x), # input must be of class 'glm'
            is.logical(robust)) # robust argument must be logical
  
  waldChi2 <- function(x){
    # Get the coefficients of the non-intercept parameters 
    b <- matrix(coef(x)[2:length(coef(x))])
    # Get the covariance matrix of terms in b
    V <- vcov(x)[2:nrow(vcov(x)),2:nrow(vcov(x))]
    # Create the R matrix for the 3 linear hypothesis
    R <- matrix(0, nrow = nrow(b), ncol = nrow(b))
    # Only the diagonal in R needs to be filled in
    diag(R) <- 1
    # Create a vector of values Rb = r
    r <- 0
    # Calculate Wald statistics
    chi2 <- as.numeric(t((R%*%b - r)) %*% (solve(R %*% V %*% t(R))) %*% (R%*%b - r))
    
    return(chi2)
  }
  
  preds <- unlist(strsplit(as.character(x$formula[3]), # extract predictors used
                           split = "[[:space:]]\\+[[:space:]]"))
  LL <- stats::logLik(x) # log likelihood
  y <- as.character(x$formula[2]) # outcome variable
  tStat <- if(robust == FALSE){
    with(x, null.deviance - deviance) # LR chi-square test statistic
  }
  else(
    waldChi2(x) # Wald chi-square test statistic
  )
  McF <- signif(1 - stats::logLik(x)/stats::logLik(glm(as.formula(paste(y, "1", sep = "~")), # McFadden's Pseudo R^2
                                                       family = poisson(link = "log"), data = x$data)), digits = 4)
  AIC <- stats::AIC(x) # Akaike information criterion
  BIC <- stats::BIC(x) # Bayesian Information Criterion
  pval <- round(with(x, stats::pchisq(tStat, # p-value of model
                                      df.null - df.residual, lower.tail = FALSE)), digits = 4)
  
  mod_stats <- merge(summary(x)$coefficients, confint.default(x),
                     by = "row.names", sort = FALSE) # model stats
  
  if(robust == TRUE){
    rse <- sqrt(diag(sandwich::vcovHC(x, type="HC0"))) # Robust Standard Error
    
    mod_stats <- subset(mod_stats,
                        select = -3) # drop 'Std. Error'
    
    # robust statistics
    mod_stats$`z value` <- round(coef(x) / rse, digits = 2)
    mod_stats$`Pr(>|z|)` <-  round(2 * stats::pnorm(abs(stats::coef(x)/rse), lower.tail=FALSE), 
                                   digits = 3)
    mod_stats$`2.5 %` <- stats::coef(x) - stats::qnorm(0.975, lower.tail = T) * rse
    mod_stats$`97.5 %` <- stats::coef(x) + stats::qnorm(0.975, lower.tail = T) * rse
    mod_stats$`Robust Std. Error` <- rse # add 'Robust Std. Error'
    mod_stats <- mod_stats[,c(1:2, ncol(mod_stats),3:(ncol(mod_stats)-1))] # reorder columns
  }
  
  if(irr == TRUE){
    mod_stats$Estimate <- exp(mod_stats$Estimate)
    mod_stats$`2.5 %` <- exp(mod_stats$`2.5 %`)
    mod_stats$`97.5 %` <- exp(mod_stats$`97.5 %`)
    # mod_stats$`Robust Std. Error` <- msm::deltamethod(list(~ exp(x1), ~ exp(x2), ~ exp(x3), ~ exp(x4)), coef(x),
    #                                sandwich::vcovHC(x, type="HC0"))
    
    names(mod_stats) <- c("Row.names", "IRR", "Delta Std. Error",
                          "z value", "Pr(>|z|)", "2.5 %", "97.5 %")
  }
  
  tbl <- data.frame(nrow = length(preds), ncol = 5) # data.frame
  
  output <- list(LL, y, tStat, McF, AIC, BIC, pval, tbl) # list of diagnostics
  names(output) <- c("log likelihood", "outcome", "chi2", "Pseudo R^2",
                     "AIC", "BIC", "Prob > chi2","results") # names for list
  
  output$results <- mod_stats
  
  return(output)
}

# To Do
## Fix Robust Std. Error using Delta Method when arg 'irr = TRUE'
## Fix Pseudo R^2 when using Poisson Regression model w/ offset

lincom <- function(x, linfct, exp = FALSE, ...){
  stopifnot("glm" %in% class(x), # input must be of class 'glm'
            is.logical(exp))  # robust argument must be logical
  
  linComb <- multcomp::glht(x, linfct, ...)
  linSummary <- summary(linComb)
  df <- setNames(data.frame(Estimate = linSummary$test$coefficients,
             sigma = linSummary$test$sigma,
             z = linSummary$test$tstat,
             pval= linSummary$test$pvalues),
           c("Estimate", "Std. Err", "z", "P>|z|"))
  Confint <- stats::confint(linSummary)$confint[,2:3]
  Confint <- matrix(Confint, ncol = 2)
  colnames(Confint) <- c("2.5 %", "97.5 %")
  df <- cbind(df, Confint)
  
  if(exp == TRUE){
    df <- apply(df[c(1, 5:6)], 2, exp)
  }
  return(df)
}

poisson_GOF <- function(x, type = c("deviance","pearson")){
  if(missing(type)){
    type <- "deviance" # default arg 'type = "deviance"'
  }
  stopifnot(class(x)[1] == "glm", # input must be of class 'glm'
            class(type) == "character", # type arg must be 'character'
            type == "deviance" | type == "pearson")
  
  if(type == "deviance"){
    # Deviance based likelihood ratio test: $\chi^2_D$ 
    cat("Goodness-of-fit chi2 = ", x$deviance,
        paste0("\nProb > chi2(",x$df.residual,") = "), pchisq(x$deviance, df=x$df.residual, lower.tail = F))
  }
  if(type == "pearson"){
    # Pearson goodness of fit: $\chi^2_P$
    y <- as.character(x$formula[2]) # outcome variable
    y_j <- x$y
    e_ep_j <- predict(x, type = "response")
    cat("Goodness-of-fit chi2 = ", sum((y_j - e_ep_j)^2/e_ep_j),
        paste0("\nProb > chi2(",x$df.residual,") = "),
        pchisq(sum((y_j - e_ep_j)^2/e_ep_j), df=x$df.residual, lower.tail = F))
  }
}

lrt <- function(reduced, full){ # important to provide reduced model in correct argument
  calc <- stats::anova(reduced, full)
  LR_chi <- calc$Deviance[2] # Test Statistic
  DF <- calc$Df[2] # degree of freedom
  
  pval <- round(stats::pchisq(q = LR_chi, df = DF, lower.tail = F), digits = 4)
  
  cat(paste0("chi2(", DF,")=",signif(LR_chi, digits = 4),
      "\nProb > chi2 = ", pval))
  
  # result <- list(LR_chi, DF, pval)
  # names(result) <- c("LR chi2", "df", "Prob > chi2")
  # return(result)
}
```


**Question:**  A study was designed to identify variables associated with tumor penetration of prostatic capsule in patients with prostate cancer.  Data were collected from an academic affiliated cancer center.  For this assignment, the dataset was modified to include 380 patients and a subset of variables from the main study.  Of the 374 patients, 151 had a cancer that penetrated the prostatic capsule.  These are the same data we used for DA4.

Answer the following questions and justify your answers.  Interpretations are necessary!

## Question 1

Generate a histogram of the outcome variable and comment on the shape.  Summarize the outcome variable using summary statistics.  Based on these two analyses, is linear regression appropriate?  What type of regression do you think is necessary to answer the remaining questions?

```{r, warning=FALSE}
psych::describe(DA6, fast = TRUE)
```

```{r}
p <- ggplot(DA6)

scotts <- ((3.5 * sd(DA6$visit)) / (nrow(DA6) ^ (1/3)))

p + aes(x = visit) +
  geom_histogram(colour = 'black', fill = 'khaki', 
                 binwidth = scotts, aes(y = ..density..)) +
  labs(title = "Distribution of Visits") +
  theme_bw()
```

Comments: outcome variable VISIT is a count variable which follows a Poisson distribution. Linear regression is not appropriate here due to the skewness of visit.

## Question 2

Fit a Poisson model that estimates the expected number of physician office visits adjusting for health status, sex, race, condition of limiting activities of living, race, private insurance information, age, chronic conditions, and education and provide appropriate assessment of this dataset by determining if the assumptions of this are violated. HINT:  Is Poisson regression appropriate?

```{r}
fit1 <- glm(visit ~ health + sex + adldiff + race + privins + age + cond + edu,
            family = poisson(link = "log"), data = DA6)

log_summary(fit1)
```

From #1, the unadjusted mean and variance of VISIT show that the variance is much greater than mean, indicating that there is a potential issue of overdispersion.   However, we haven’t learned yet how to deal with that so we will move ahead with Poisson.

## Question 3

Using Poisson regression, perform likelihood ratio tests or Wald tests to identify whether health status, sex, race, condition of limiting activities of living, race, private insurance information, age, chronic conditions, and education are univariably associated with the mean number of physician office visits. (This means to fit single models, one for each of those covariates).

```{r}
fit2 <- update(fit1, .~health)
fit3 <- update(fit1, .~sex)
fit4 <- update(fit1, .~race)
fit5 <- update(fit1, .~adldiff)
fit6 <- update(fit1, .~privins)
fit7 <- update(fit1, .~age)
fit8 <- update(fit1, .~cond)
fit9 <- update(fit1, .~edu)
fitNull <- update(fit1, .~1)
```

```{r}
log_summary(fit2)
lrt(fitNull, fit2)
```

```{r}
log_summary(fit3)
lrt(fitNull, fit3)
```

```{r}
log_summary(fit4)
lrt(fitNull, fit4)
```

```{r}
log_summary(fit5)
lrt(fitNull, fit5)
```

```{r}
log_summary(fit6)
lrt(fitNull, fit6)
```

```{r}
log_summary(fit7)
lrt(fitNull, fit7)
```

```{r}
log_summary(fit8)
lrt(fitNull, fit8)
```

```{r}
log_summary(fit9)
lrt(fitNull, fit9)
```

So it appears as if all of these variables are univariably important to the prediction of visit.

## Question 4

Fit a multivariable model that describes the data given the information from #3 (don’t consider interactions) using a backward stepwise approach and complete the following with appropriate interpretation:

Adjusted for the other independent variables, what is the estimated ratio of 
number of physician office visits for those who reported an excellent health condition to those who reported a poor health condition.

```{r}
pred <- cat("~", as.character(fit1$formula[3], split = "[[:space:]]\\+[[:space:]]"))

(fitStep <- step(fit1, direction = "backward", scope = list(lower ~ 1, upper = pred)))
```

Adjusted for the other independent variables, what is the estimated ratio of 
number of physician office visits for those who reported an excellent health condition to those who reported a poor health condition. Briefly interpret the result.

```{r}
lincom(fitStep, linfct= c("health3 = 0"), exp = T)
```

Reporting excellent health results in a `r signif(1 - 0.5608378, digits = 2) * 100`% lower expected number of physician office visits compared to those who report poor health.

## Question 5

Perform the global goodness of fit of the model from #4 and assess the diagnostics for this model.  Are there problematic points?  Do you think there is a problem with this model?  HINT:  recall what you saw in #1.

```{r}
poisson_GOF(fit1)
```

```{r}
poisson_GOF(fit1, type = "pearson")
```

We have significant lack of fit.

```{r}
DA6$resid <- resid(fit1, type = "pearson")
DA6$hat <- hatvalues(fit1)
DA6$adjres <- with(DA6, resid / sqrt(1 - hat))
DA6$dist <- cooks.distance(fit1)
DA6$index <- 1:nrow(DA6)
DA6 <- DA6[, c(ncol(DA6), 2:(ncol(DA6) - 1))]
```

```{r}
p <- ggplot(DA6)

p + aes(x = index, y = adjres) +
  geom_hline(yintercept = 0, colour = "red") +
  geom_hline(yintercept = 2, colour = "red") +
  geom_hline(yintercept = -2, colour = "red") +
  geom_point(colour = "darkblue") +
  labs(title = "Adjusted Residuals",
       x = "Index", y = "Adjusted Pearson Residual") +
  theme_bw()

hRes <- nrow(subset(DA6, adjres >= 2 | adjres <= -2))
```

There are `r hRes` adjusted residuals that are greater than $\mid{x}\mid = 2$.

```{r}
nPred <- length(unlist(strsplit(as.character(fit1$formula[3]), # number of predictors in model
                                split = "[[:space:]]\\+[[:space:]]")))
hat_cutoff <- 2 * (nPred + 1) / nrow(fit1$data)

p + aes(x = index, y = hat) +
  geom_hline(yintercept = hat_cutoff, colour = "red") +
  geom_point(colour = "darkblue") +
  labs(title = "Leverage",
       x = "Index", y = "Hat Diagonal") +
  theme_bw()

hLev <- nrow(subset(DA6, hat >= hat_cutoff)) # number of high leverage points
```

There are `r hLev` points with high leverage, exceeding `r hat_cutoff`.

```{r}
cooks_cutoff <- 4 / nrow(fit1$data)

p + aes(x = index, y = dist) +
  geom_hline(yintercept = cooks_cutoff, colour = "red") +
  geom_point(colour = "darkblue") +
  labs(title = "Cook's Distance",
       x = "Index", y = "Cook's D") +
  theme_bw()

hDist <- nrow(subset(DA6, dist >= cooks_cutoff))
```

There are `r hDist` points with high influence, exceeding the Cook's D cutoff of `r cooks_cutoff`.

There are no cooksd values >1 however there are a few points that are much larger than the rest so they could be problematic.

Weighing all of the evidence it appears that this model is not a good one.  There is significant lack of fit and quite a few problematic points.  We do know that the data are overdispersed so that is most likely the issue.